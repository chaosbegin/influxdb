// This module will house the gRPC server implementation for the DistributedQueryService.

use std::pin::Pin;
use std::sync::Arc;
use tokio_stream::Stream;
use tonic::{Request, Response, Status, Streaming};
use futures::StreamExt;

use arrow::ipc::writer::{StreamWriter, IpcWriteOptions};
use arrow::record_batch::RecordBatch;
use datafusion::logical_expr::LogicalPlan;
use datafusion::execution::SendableRecordBatchStream;

use influxdb3_internal_api::query_executor::QueryExecutor; // Assuming this is the correct trait path

// Include the Rust code generated by tonic_build from the .proto file.
pub mod generated_distributed_query {
    #![allow(clippy::enum_variant_names)]
    #![allow(clippy::derive_partial_eq_without_eq)]
    tonic::include_proto!("influxdb3.internal.distributed_query.v1");
}

pub use generated_distributed_query::{
    distributed_query_service_server::{DistributedQueryService, DistributedQueryServiceServer},
    ExecuteQueryFragmentRequest, ExecuteQueryFragmentResponse,
};

#[derive(Debug)]
pub struct DistributedQueryServerImpl {
    query_executor: Arc<dyn QueryExecutor>, // Using the trait defined in influxdb3_internal_api
}

impl DistributedQueryServerImpl {
    pub fn new(query_executor: Arc<dyn QueryExecutor>) -> Self {
        Self { query_executor }
    }
}

#[tonic::async_trait]
impl DistributedQueryService for DistributedQueryServerImpl {
    type ExecuteQueryFragmentStream =
        Pin<Box<dyn Stream<Item = Result<ExecuteQueryFragmentResponse, Status>> + Send + Sync + 'static>>;

    async fn execute_query_fragment(
        &self,
        request: Request<ExecuteQueryFragmentRequest>,
    ) -> Result<Response<Self::ExecuteQueryFragmentStream>, Status> {
        let req = request.into_inner();
        observability_deps::tracing::info!(
            db_name = %req.db_name,
            shard_id = %req.shard_id,
            plan_json_len = %req.logical_plan_fragment_json.len(),
            "Received ExecuteQueryFragment request"
        );

        // 1. Deserialize LogicalPlan
        let logical_plan_fragment: LogicalPlan = match serde_json::from_str(&req.logical_plan_fragment_json) {
            Ok(plan) => plan,
            Err(e) => {
                let msg = format!("Failed to deserialize LogicalPlan fragment: {}", e);
                observability_deps::tracing::error!("{}", msg);
                return Err(Status::invalid_argument(msg));
            }
        };

        // 2. Create IOxSessionContext (this is a critical part for shard-awareness)
        // For now, we get a general context. The actual shard filtering needs to happen
        // during physical planning or via a shard-aware TableProvider.
        let session_ctx = self.query_executor.new_context_for_db(&req.db_name, None, Default::default())
            .map_err(|e| Status::internal(format!("Failed to create session context: {}", e)))?;

        // Apply session_config from request
        for (k,v) in req.session_config {
            session_ctx.inner().set_config_option(&k, &v)
                .map_err(|e| Status::invalid_argument(format!("Failed to set session config {}: {}", k, e)))?;
        }

        // TODO: Make the session_ctx/TableProvider truly shard-aware using req.shard_id.
        // This is a placeholder for where such logic would integrate. For example,
        // session_ctx.set_target_shard(req.shard_id);
        // Or, the catalog provider used by the session_ctx would need to be
        // pre-filtered or aware of a target shard_id.

        // 3. Create Physical Plan
        let exec_plan = match session_ctx.create_physical_plan(&logical_plan_fragment).await {
            Ok(plan) => plan,
            Err(e) => {
                let msg = format!("Failed to create physical plan from fragment: {}", e);
                observability_deps::tracing::error!("{}", msg);
                return Err(Status::internal(msg));
            }
        };

        // 4. Execute Plan
        let mut result_stream = match session_ctx.execute_stream(exec_plan).await {
            Ok(stream) => stream,
            Err(e) => {
                let msg = format!("Failed to execute plan fragment: {}", e);
                observability_deps::tracing::error!("{}", msg);
                return Err(Status::internal(msg));
            }
        };

        // 5. Stream Results
        let output_stream = async_stream::try_stream! {
            while let Some(batch_result) = result_stream.next().await {
                match batch_result {
                    Ok(batch) => {
                        if batch.num_rows() == 0 {
                            // Skip empty batches to avoid sending empty responses
                            continue;
                        }
                        let mut
            ipc_bytes = Vec::new();
                        let options = IpcWriteOptions::default();
                        // It's typical to use a new StreamWriter for each batch in a streaming response
                        // if each response message is self-contained.
                        {
                            let mut writer = StreamWriter::try_new_with_options(&mut ipc_bytes, batch.schema().as_ref(), options.clone())?;
                            writer.write(&batch)?;
                            writer.finish()?;
                        } // writer is dropped, ipc_bytes contains the complete message for this batch

                        yield ExecuteQueryFragmentResponse {
                            record_batch_ipc_bytes: ipc_bytes,
                            error_message: None,
                        };
                    }
                    Err(e) => {
                        let err_msg = format!("Error executing query fragment stream: {}", e);
                        observability_deps::tracing::error!("{}", err_msg);
                        // Send error as the last message in the stream
                        yield ExecuteQueryFragmentResponse {
                            record_batch_ipc_bytes: Vec::new(),
                            error_message: Some(err_msg.clone()),
                        };
                        // Optionally, re-throw error to terminate stream with Status if preferred
                        // Err(Status::internal(err_msg))?;
                        break;
                    }
                }
            }
        };

        Ok(Response::new(Box::pin(output_stream) as Self::ExecuteQueryFragmentStream))
    }
}
