// This module will house the gRPC server implementation for the DistributedQueryService.

// Include the Rust code generated by tonic_build from the .proto file.
pub mod generated_distributed_query {
    #![allow(clippy::enum_variant_names)]
    #![allow(clippy::derive_partial_eq_without_eq)]
    tonic::include_proto!("influxdb3.internal.query.v1");
}

// Re-export for easier use.
pub use generated_distributed_query::{
    distributed_query_service_server::{DistributedQueryService, DistributedQueryServiceServer},
    ExecuteQueryFragmentRequest,
    // FlightData is imported from arrow_flight::flight_service_server in consuming code typically
};
// Note: arrow::flight::protocol::FlightData would be used for the stream type.
// tonic::include_proto! should handle making arrow_flight types available if arrow-flight feature is enabled in tonic-build
// or if arrow-flight crate's generated types are correctly referenced.

use std::pin::Pin;
use std::sync::Arc;
use futures::Stream;
use tonic::{Request, Response, Status, Streaming};
use arrow_flight::FlightData; // Correct import for FlightData
use datafusion::physical_plan::SendableRecordBatchStream;
use datafusion::prelude::SessionContext; // For creating a new session context per request
use influxdb3_internal_api::query_executor::QueryExecutor; // Assuming QueryExecutorImpl is behind this trait

// Define the server struct
#[derive(Debug)]
pub struct DistributedQueryServerImpl {
    // QueryExecutor is likely Arc<dyn QueryExecutor> or Arc<QueryExecutorImpl>
    query_executor: Arc<dyn QueryExecutor>,
    // We might need direct access to the IOxSessionContext or Executor if QueryExecutor trait is too high-level
    // For now, assuming QueryExecutor can provide what we need or can be adapted.
}

impl DistributedQueryServerImpl {
    pub fn new(query_executor: Arc<dyn QueryExecutor>) -> Self {
        Self { query_executor }
    }
}

type FlightDataStream = Pin<Box<dyn Stream<Item = Result<FlightData, Status>> + Send>>;

#[tonic::async_trait]
impl DistributedQueryService for DistributedQueryServerImpl {
    type ExecuteQueryFragmentStream = FlightDataStream;

    async fn execute_query_fragment(
        &self,
        request: Request<ExecuteQueryFragmentRequest>,
    ) -> Result<Response<Self::ExecuteQueryFragmentStream>, Status> {
        let req = request.into_inner();
        observability_deps::tracing::info!(
            database_name = %req.database_name,
            shard_id = ?req.shard_id,
            query_id = %req.query_id,
            "Received ExecuteQueryFragment request"
        );

        // 1. Deserialize plan_bytes into a DataFusion ExecutionPlan.
        //    THIS IS A MAJOR CONCEPTUAL STEP. ExecutionPlan serialization/deserialization is complex
        //    and not directly supported by DataFusion in a stable, portable way across versions/nodes.
        //    A real implementation might send a simplified plan representation, a SQL query fragment,
        //    or use something like Substrait.
        //    For this placeholder, we'll assume it's a SQL query fragment for simplicity of "execution".
        let query_fragment = match String::from_utf8(req.plan_bytes) {
            Ok(s) => s,
            Err(e) => {
                observability_deps::tracing::error!("Failed to deserialize plan_bytes as String: {}", e);
                return Err(Status::invalid_argument(format!("Invalid plan_bytes (not UTF-8 string): {}", e)));
            }
        };

        observability_deps::tracing::info!("Executing query fragment: {}", query_fragment);

        // 2. Create a new IOxSessionContext for this request.
        //    The QueryExecutor should provide a way to get a new session context,
        //    or be able to execute a query against a specific DB with session properties.
        //    This part is also conceptual as the QueryExecutor trait might not directly expose this.
        //    For now, we'll use the existing query_sql method on QueryExecutor.

        // TODO: Apply req.session_config to the session context.

        let record_batch_stream: SendableRecordBatchStream = match self.query_executor
            .query_sql(
                &req.database_name,
                &query_fragment, // Assuming plan_bytes was a SQL string for this placeholder
                None, // No statement params for this simplified fragment
                None, // No explicit parent span_ctx from request for now
                None, // No external_span_ctx
            )
            .await
        {
            Ok(stream) => stream,
            Err(e) => {
                observability_deps::tracing::error!("Error executing query fragment: {}", e);
                return Err(Status::internal(format!("Failed to execute query fragment: {}", e)));
            }
        };

        // 3. Convert SendableRecordBatchStream to a stream of FlightData.
        //    This is also a complex step involving creating FlightData messages from RecordBatches and schema.
        //    Arrow Flight utilities would typically be used here.
        //    Conceptual placeholder:
        let output_stream = futures::stream::once(async {
            Err(Status::unimplemented("FlightData streaming not fully implemented"))
        });
        // A more realistic (but still simplified) approach:
        // let schema = record_batch_stream.schema(); // Schema of the results
        // let flight_data_stream = record_batch_stream.map_ok(move |batch| {
        //     // Simplified: This doesn't include schema in every FlightData, which might be needed
        //     // or schema sent once. Arrow Flight has specific ways to do this.
        //     let (flight_dictionaries, flight_batch) = arrow_flight::utils::flight_data_from_arrow_batch(&batch, &HashMap::new());
        //     // In a real stream, dictionaries would be sent first, then batches.
        //     flight_batch // This is simplified. A real implementation sends dictionaries first.
        // }).map_err(|e| Status::internal(format!("Error converting batch to FlightData: {}", e)));

        // For now, returning an empty stream with an unimplemented message.
        let response_stream: FlightDataStream = Box::pin(output_stream);
        Ok(Response::new(response_stream))
    }
}

// Conceptual integration into server startup (from lib.rs or server.rs):
//
// use crate::distributed_query_service::{DistributedQueryServerImpl, DistributedQueryServiceServer};
// // ...
// let query_executor_arc = ... ; // Arc<dyn QueryExecutor> or Arc<QueryExecutorImpl>
// let distributed_query_server = DistributedQueryServerImpl::new(query_executor_arc);
// // ... in tonic server builder:
// // .add_service(DistributedQueryServiceServer::new(distributed_query_server))
